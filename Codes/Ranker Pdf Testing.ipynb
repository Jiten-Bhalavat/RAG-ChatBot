{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Models Used:  \n",
    "1.) LLM = Gpt-3.5-turbo  \n",
    "2.) Embeddings = BAAI/bge-large-en-v1.5  \n",
    "3.) Re-Ranker = BAAI/bge-reranker-large      \n",
    "\n",
    "        Steps :     \n",
    "1.) Loading the data   \n",
    "2.) Creating the nodes   \n",
    "3.) HuggingFace Embeddings and LLM Model( Opensource as well) --> Service Context  \n",
    "4.) Sentence Indexing and Storing it for further use  \n",
    "5.) Re-Ranking (Bge-Large)  \n",
    "6.) Query Engine with Re-Ranking  \n",
    "7.) Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Desktop\\Jiten\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded documents with 15 documents\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = []\n",
    "# for title in titles:\n",
    "\n",
    "loaders=[\n",
    "    SimpleDirectoryReader(input_files=[r\"C:\\Users\\ASUS\\Desktop\\Jiten\\Hybrid Search\\DATA\\pdf testing.pdf\"]),\n",
    "]\n",
    "\n",
    "for loader in loaders:\n",
    "    documents.extend(loader.load_data())\n",
    "\n",
    "# documents = SimpleDirectoryReader(input_files=[r\"C:\\Users\\ASUS\\Desktop\\Jiten\\Data\\RIL-70_compressed-1-50-1-20.pdf\"]).load_data()\n",
    "print(f\"loaded documents with {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(documents[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Creating the Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "\n",
    "def create_nodes(documents, chunk_size=500, chunk_overlap=100):\n",
    "  node_parser = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  nodes = node_parser.get_nodes_from_documents(documents)\n",
    "  return nodes\n",
    "\n",
    "nodes1 = create_nodes(documents)\n",
    "# print(len(nodes1)) # 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### No need of (Service context) if you are using OpenAI Embeddings as it by default Consider it as OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dont run next cell , the Embeddings are stored in the folder, use that directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11644\\562111050.py:8: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  ctx = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "#### Dont RUN, unless, running it for the first time\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "#define LLM and embedding model\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-large-en-v1.5\",\n",
    ")\n",
    "\n",
    "sentence_index = VectorStoreIndex(nodes1, service_context=service_context)\n",
    "\n",
    "# sentence_index.storage_context.persist(r\"C:\\Users\\ASUS\\Desktop\\Jiten\\Resume Data\\Resume_Embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Cell, if the Embeddings are stored in the Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    load_index_from_storage,\n",
    "    StorageContext,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(\n",
    "            persist_dir=r\"C:\\Users\\ASUS\\Desktop\\Jiten\\Embeddings\")\n",
    "# load index\n",
    "sentence_index = load_index_from_storage(storage_context,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-ranking using BGE-Reranker-Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.indices.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "from llama_index.core.postprocessor.sbert_rerank import SentenceTransformerRerank\n",
    "bge_reranker_large= SentenceTransformerRerank(model=\"BAAI/bge-reranker-large\", top_n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Without Re-Ranker\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "metadata_query_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    # the target key defaults to `window` to match the node_parser's default\n",
    "    node_postprocessors=[\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## With Re-Ranker\n",
    "\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "reranker_query_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    # the target key defaults to `window` to match the node_parser's default\n",
    "    node_postprocessors=[\n",
    "        bge_reranker_large\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data analysis reveals that the number of accesses for different groups of datasets varies significantly. The time series data shows that each group, such as HIGGD, SUSY, and TOPQ, has its own distinct access pattern. The access patterns for these popular groups demonstrate continuous access throughout the time interval. Additionally, the time series for a single dataset indicates discrete access with numerous random omissions. The study evaluates two predictive approaches: regression predictions for groups of datasets and classification for individual datasets. By representing datasets as time series sequences, it becomes evident that each dataset group or specific dataset can be effectively portrayed as a sequence of data accesses over a certain period of time.\n",
      "--------\n",
      "Node ID: 086c77e1-641f-42a8-90ff-0ee5720261ed\n",
      "Text: EXPLORING HIERARCHICAL FORECASTING 3079 0 2017 2018 2019 2020\n",
      "Date2021 2022HIGGD SUSY TOPQ 2023500010 00015 00020 00025 00030\n",
      "000Number of accesses Fig. 4. The number of accesses for the di ﬀerent\n",
      "groups of datasets. However, none of the predictive methods developed\n",
      "to make decisions about data replication, data placement, and other\n",
      "data managem...\n",
      "Score:  0.435\n",
      "\n",
      "Node ID: 0e67e7d8-03c5-4750-9e35-6dfb730a9cc7\n",
      "Text: 3080 GRIGORIEVA et al. Date2022-01 2021-09 2021-05 2021-01\n",
      "2020-09 2020-05 2020-01 2019-09 2019-05 2019-01 2018-09Number of\n",
      "accesses 050100150200250300350 Fig. 5. Accesses of a speci ﬁc dataset.\n",
      "LetDi={ni,t,ni,t+1,ni,t+2,...}is access pattern of ithdataset, where\n",
      "ni,tis the number of accesses to the dataset for tthweek. Then, the\n",
      "time series for...\n",
      "Score:  0.217\n",
      "\n",
      "Node ID: 14d7737a-18f7-406e-8fba-bc81a8e89198\n",
      "Text: EXPLORING HIERARCHICAL FORECASTING 3077 0 Data groupsn_tasks 500\n",
      "0001 000  0001 500  0002 000  0002 500  0003 000  000 SUSY HIGGD EXOT\n",
      "TOPQ STDM JETM PHYS EGAM BPHY FTAGNumber of accesses Fig. 1. The\n",
      "popularity of groups of datasets. •On the other hand, user analysis is\n",
      "based on derived datasets and is conducted by researchers who may\n",
      "access th...\n",
      "Score:  0.121\n",
      "\n",
      "Node ID: 7659e887-29ea-4c79-824b-db1d455d4f3e\n",
      "Text: If the number of accesses is greater than one, it is classi ﬁed\n",
      "as “1,”and if there are no accesses, it is classi ﬁed as “0.” The\n",
      "total number of datasets is around 1 000 000, but we have excluded\n",
      "data that are rarely used (datasets that have less than 30 accesses\n",
      "during the w hole period). The total number of weeks in each dataset\n",
      "is 300. Thus,...\n",
      "Score:  0.051\n",
      "\n",
      "Node ID: 10d7d1b4-31c0-4ebd-b19b-09213a898c00\n",
      "Text: And, then, search for the most popular datasets within each of\n",
      "these groups. 2. DATASETS POPULARITY STATISTICAL RESEARCH We analyzed\n",
      "a fragment of data from one of the l argest HEP experiments at the\n",
      "LHC. The data sample has about one million datasets1)that have been\n",
      "accessed at least once during the last 5 years. Figure 1 illustrates\n",
      "the catego...\n",
      "Score:  0.019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "responseranker = reranker_query_engine.query(\" Provide me the insights of \\\"Number of accesses versus Number of accesses for the Different group of datasets in detail\\\"\")\n",
    "print(str(responseranker))\n",
    "print(\"--------\")\n",
    "\n",
    "for i in range(len(responseranker.source_nodes)):\n",
    "    print(responseranker.source_nodes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one-step prediction involves predicting one new point (a value for the future week) based on several past points. In the context of LSTM forecasting models, the LSTM layer consists of blocks with sigmoid and tanh activation functions that give values in the range of [-1, 1]. However, since the values in the input time series are positive and can reach high numbers, a transformation is applied to the data before forecasting. This transformation involves taking the difference of the logarithm of the current value and the previous value for each time moment. Additionally, the LSTM model's hidden state dimension (nunits) is a hyperparameter that is typically chosen to balance model complexity and prediction time.\n",
      "--------\n",
      "Node ID: 824f79a1-cdf5-47b4-a785-e0eb8f24ecbd\n",
      "Text: 7. POPULARITY OF DATASET GROUPS OF HIGH ENERGY PHYSICS\n",
      "EXPERIMENTS Predicting the popularity of a group of datasets is\n",
      "crucial for e ﬃcient search and analysis. We used data accesses time\n",
      "series for the past ﬁve years and employed two models, namely LSTM and\n",
      "Facebook Prophet, to address t his regression problem. 7.1. LSTM\n",
      "Forecast Model for the ...\n",
      "Score:  0.404\n",
      "\n",
      "Node ID: 26ac5341-c5a1-40a4-a2dc-90ad40c42a56\n",
      "Text: EXPLORING HIERARCHICAL FORECASTING 3083 Date45678Log N_Tasks\n",
      "2023-02Actual log(n_tasks + 1) Train predictedTest predicted 2022-12\n",
      "2023-01 2022-11 2022-10 2022-09 2022-08 2022-07 Fig. 7. One-step\n",
      "prediction by LSTM-based model for time-series of SUSY format. Every\n",
      "next point are predicted based on actual previous data. Actual\n",
      "log(n_tasks + 1) Mul...\n",
      "Score:  0.163\n",
      "\n",
      "Node ID: 2930ef17-db37-4796-b288-53ab52e534a3\n",
      "Text: EXPLORING HIERARCHICAL FORECASTING 3085 Table 3. Symmetric mean\n",
      "absolute percentage error) metr ic) for LSTM and Facebook Prophet\n",
      "models in com- parison with the Naive forecast for three di ﬀerent\n",
      "groups of datasets represented with logarithmic transformation Model\n",
      "Type of Prediction  No. weeks  HIGGD, %  TOPQ,%  SUSY,% LSTM One-step\n",
      "1  7.21  ...\n",
      "Score:  0.033\n",
      "\n",
      "Node ID: ce2c3dfa-a5ad-41a2-95b2-0e450abc80f6\n",
      "Text: 7.1.3. Multi-output prediction. The multi-output LSTM model may\n",
      "have the following form: LSTM cell, that returns whole sequence, 1D\n",
      "max-poo ling layer along the time axis, dense layer with nforecasts\n",
      "output neurons (where nforecasts is a number of future weeks to\n",
      "forecast). Figure 9 demonstrates an example of multi-ou tput\n",
      "prediction for 12 week...\n",
      "Score:  0.006\n",
      "\n",
      "Node ID: 3f4aa021-5fd2-4aae-9fd3-f624588dd4db\n",
      "Text: 3084 GRIGORIEVA et al. Actual log(n_tasks + 1) Multi-output\n",
      "prediction Date2023-02 2022-12 2023-01 2022-11 2022-10 2022-09 2022-08\n",
      "2022-0745678Log N_Tasks Fig. 9. Multi-output prediction by LSTM-based\n",
      "model for time -series of SUSY format. Prediction for 12 weeks in the\n",
      "future. Actual log(n_tasks + 1) Train predictedTest predicted\n",
      "Date2023-02 20...\n",
      "Score:  0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "responseranker = reranker_query_engine.query(\" Provide me detailed information about the One step prediction\")\n",
    "print(str(responseranker))\n",
    "print(\"--------\")\n",
    "\n",
    "for i in range(len(responseranker.source_nodes)):\n",
    "    print(responseranker.source_nodes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA/SARIMA, Facebook Prophet, Logistic Regression, Random Forest, SVM (Support Vector Machine), LSTM (Long Short-Term Memory)\n",
      "--------\n",
      "Node ID: 22d5682c-a5aa-4326-9818-499261396659\n",
      "Text: 3082 GRIGORIEVA et al. Table 2. Existing algorithms used for\n",
      "time series prediction Class of models Implementation  Description\n",
      "Statistical ARIMA/SARIMA [6] ARIMA (Autoregressive Integrated Moving\n",
      "Average) is successor of ARMA (Autoregressive Moving Average) model.\n",
      "It combines Autoregression and Moving average models together, and\n",
      "applies them f...\n",
      "Score:  0.992\n",
      "\n",
      "Node ID: daf69bb5-9462-42b1-9574-719c64bb3c29\n",
      "Text: This is so far the most important metric, as in the most cases\n",
      "alogrithm is expected to pr edict accesses for known long-living\n",
      "datasets, that can be used to train model as well. 2.Next week\n",
      "prediction on test . The general dataset is divided into train and\n",
      "test subsamples. The proposed methods are trained on [Abefore,Aweek\n",
      "_id]trainand predict ...\n",
      "Score:  0.310\n",
      "\n",
      "Node ID: 824f79a1-cdf5-47b4-a785-e0eb8f24ecbd\n",
      "Text: 7. POPULARITY OF DATASET GROUPS OF HIGH ENERGY PHYSICS\n",
      "EXPERIMENTS Predicting the popularity of a group of datasets is\n",
      "crucial for e ﬃcient search and analysis. We used data accesses time\n",
      "series for the past ﬁve years and employed two models, namely LSTM and\n",
      "Facebook Prophet, to address t his regression problem. 7.1. LSTM\n",
      "Forecast Model for the ...\n",
      "Score:  0.151\n",
      "\n",
      "Node ID: 3f4aa021-5fd2-4aae-9fd3-f624588dd4db\n",
      "Text: 3084 GRIGORIEVA et al. Actual log(n_tasks + 1) Multi-output\n",
      "prediction Date2023-02 2022-12 2023-01 2022-11 2022-10 2022-09 2022-08\n",
      "2022-0745678Log N_Tasks Fig. 9. Multi-output prediction by LSTM-based\n",
      "model for time -series of SUSY format. Prediction for 12 weeks in the\n",
      "future. Actual log(n_tasks + 1) Train predictedTest predicted\n",
      "Date2023-02 20...\n",
      "Score:  0.139\n",
      "\n",
      "Node ID: 26ac5341-c5a1-40a4-a2dc-90ad40c42a56\n",
      "Text: EXPLORING HIERARCHICAL FORECASTING 3083 Date45678Log N_Tasks\n",
      "2023-02Actual log(n_tasks + 1) Train predictedTest predicted 2022-12\n",
      "2023-01 2022-11 2022-10 2022-09 2022-08 2022-07 Fig. 7. One-step\n",
      "prediction by LSTM-based model for time-series of SUSY format. Every\n",
      "next point are predicted based on actual previous data. Actual\n",
      "log(n_tasks + 1) Mul...\n",
      "Score:  0.063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "responseranker = reranker_query_engine.query(\"\"\"\n",
    "Which are the existing algorithms used for time series prediction. Provide all\n",
    "\"\"\" )\n",
    "print(str(responseranker))\n",
    "print(\"--------\")\n",
    "\n",
    "for i in range(len(responseranker.source_nodes)):\n",
    "    print(responseranker.source_nodes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
